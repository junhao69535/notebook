# 逻辑结构管理

## 表
### 表的存储属性
TOAST是"The Oversized-Attribute Storage Technique"，用于存储一个大字段的值。由于postgresql的页面大小是固定的（通常是8KB），并且不允许行跨越多个页面。因此大的字段通常被压缩或切片成多个物理行存到另一张系统表中（TOAST表）。

### 表继承和分区表
当查询父表时，也把父表中子表的数据查询出来，反之则不行。如果只想查询父表本身的数据，则在表名前加only。

所有父表的检查约束和非空约束都会自动被所有子表继承。其他类型的约束（唯一、主键和外键）则不会被继承。

如果同一个字段名出现在多个父表中，或者同事出现在父表和子表的定义里，那么这些字段就会被"融合"。

采用SELECT、UPDATE、DELETE等命令访问或操作一张父表时，也会同时访问或操作相应的子表，二使用ALTER TABLE命令修改一张父表的结构定义时，也会同时修改子表的结构定义，但“REINDEX”、“VACUUM”命令不会影响子表。

### 分区表
postgresql是通过表继承来实现表分区的。表分区就是把逻辑上的一个大表分割成物理上的几个小块。

这里说明一下mysql的区别，mysql有分区和分表的概念。分区逻辑上还是一个表，物理上分区存储的位置可能不一样。分表逻辑上是多张表，数据实际上是存储在多个分表中，不存在父表中，物理上存储的位置都一样。而在pg里，分区表更像是mysql的分区和分表的结合。

分区表可以提供若干好处：

* 删除历史数据更快。若按时间分区，只会删除对应分区。
* 某些类型的查询性能可以得到极大提升。
* 当查询或更新一个分区的大部分记录时，连续扫描那个分区而不是使用索引离散地访问整个表，可以获得巨大的性能提升。
* 很少用到的历史数据可以使用表空间的技术移动到便宜一些的慢速存储介质上。因为使用分区表可以将不同的分区安置在不同的物理介质上。

使用分区表的基本原则，即表的大小超过了数据库服务器的物理内存大小则应该使用。

建分区表的步骤如下：
1. 创建父表，所有分区都从它继承。这个表中没有数据。
2. 创建几个子表，每个都是从主表上继承的。
3. 给分区表增加约束。
4. 对于每个分区表，在关键字字段上创建一个索引。
5. 定义一个规则或者触发器，把对主表的数据插入重定向到合适的分区表。
6. 确保constraint_exclusion里的配置参数postgresql.conf是打开的。

有两种方法可以达到往父表插入数据，自动插入对应的分区的效果。使用触发器或者规则。

规则和触发器的对比：
* 规则有显著的开销，每次检查时都会有次开销。不过批量插入时只有一次开销，所以在批量插入的情况下，其相对于触发器更有优势。
* 通过COPY插入数据不能触发规则，所以只能COPY到对应的分区表。但COPY能触发触发器。
* 如果插入数据在规则设置范围之外，将会插到主表中。如果此时希望直接报错，规则无法实现。

### 事务、并发、锁
#### 事务
##### ACID

* 原子性（atomicity）：事务必须以一个整体单元的形式进行工作，对于其数据的修改，要么全都执行，要么全都不执行。
* 一致性（consistency）：事务完成时，必须使所有的数据都保持一致状态。
* 隔离性（isolation）：事务查看数据时数据所处的状态，要么是另一并发事务修改它之前的状态，要么是另一事务修改它之后的状态，事务是不会查看中间状态的数据的。
* 持久性（durability）：事务完成之后，它对于系统的影响是永久性的。

事务一致性由主键、外键这类约束保证；持久性由预写日志（WAL）和数据库管理系统的恢复子系统保证；原子性和隔离性则由事务管理器和MVCC来控制。

在pg里中，可使用多版本并发控制（MVCC）来维护数据的一致性。相比于锁定模型，多版本并发控制的主要优点是在MVCC里对检索数据的锁请求与写数据的锁请求不冲突，读不会阻塞写，而写也不阻塞读。

##### DDL事务
pg中大多数DDL可以包含在一个事务中，而且也是可以回滚的。所以非常适合把pg作为Sharding的分布式数据系统的底层数据库。

##### SAVEPOINT
pg支持保存点（SAVEPOINT）的功能，在一个大的事务中，可以把操作过程分成几个部分，第一个部分成功后，可以建一个保存点，若后面的执行失败，则回滚到这个保存点，而不必把整个事务都回滚掉。

##### 事务隔离级别
数据库的事务隔离级别有以下四种，隔离级别底层由锁和MVCC实现：

* READ UNCOMMITED：读未提交。能读到别的事务未提交的数据。
* READ COMMITTED：读已提交。只能读到别的事务已经提交的数据。
* REPEATABLE READ：重复读。能重复读同一范围的数据。
* SERIALIZABLE：串行化。写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。粒度是行锁。

前三个隔离级别对应的并发问题是读-写。可串行化对应的并发问题是写-写。

对于并发事务，可能发生以下不一致的情况，级别从高到底如下：

* 脏读：一个事务读取了另一个未提交事务写入的数据。
* 不可重复读：指一个事务重新读取前面读取过的数据时，发现该数据已经被另一个已提交事务修改了。不可重复读针对的是UPDATE，是对相同范围的数据而言的。
* 幻读：一个事务开始后，需要根据数据库中现有的数据做一些更新，于是重新执行一个查询，返回一套符合查询条件的行，这时发现这些行因为其他最近提交的事务而发生了改变。幻读针对的是INSERT和DELETE，是针对所有数据而言。

不同事务隔离界别的行为如下表1：

表1 事务隔离级别的行为

| 隔离级别 |  脏读  | 不可重复读 |  幻读  | 序列化异常 |
| ------- | ----- | --------- | ----- | --------- |
| 读未提交 | 可能   | 可能      | 可能   | 可能      |
| 读已提交 | 不可能 | 可能      | 可能   | 可能      |
| 重复读   | 不可能 | 不可能     | 可能   | 可能      |
| 可串行化 | 不可能 | 不可能     | 不可能 | 不可能     |

序列化异常指成功提交的一组事务的执行结果与这些事务按照串行执行方式的执行结果不一样。例如事务1开始查询出id=1的数据，事务2在事务1提交之前对数据进行了更新操作，并在事务1提交之前提交成功，当事务1提交时，应该是采用事务2更新后的值，但由于事务1的事务隔离级别是可重复读，因此事务1读到的数据是事务2未提交前的数据，这时就发生序列化异常。序列化异常就是重复读后再执行更新导致的。

pg里实际只有三个隔离级别，读未提交和读提交都是读已提交事务隔离级别。剩下两个分别是重复读和可串行化。**读已提交是默认的隔离级别**。

##### 两阶段提交
在分布式系统中，多台数据库之间的原子性，需要通过两阶段提交实现。

两阶段提交协议有如下五个步骤：
1. 应用程序先调用各台数据库做一些操作，但不提交事务；然后调用事务协调器（这个协调器可能也是由应用程序自己实现的）中的提交方法。
2. 事务协调器将联络事务中涉及的每台数据库，并通知它们准备提交事务，这是第一阶段的开始。在pg里，一般是调用“PREPARE TRANSACTION”命令。
3. 各台数据库接收到“PREPARE TRANSACTION”命令后，如果要返回成功，则数据库必须将自己置于以下状态：确保后续能被要求提交事务时提交事务，或者在被要求回滚事务时回滚事务。如果数据库无法完成此事务，它会直接返回失败给事务协调器。
4. 事务协调器接收所有数据库的响应。
5. 在第二阶段。如果任一数据库在第一阶段返回失败，则事务协调器将会发一个回滚命令（ROLLBACK PREPARED）给各台数据库。如果所有数据库的响应都是成功的，则向各台数据库发送“COMMIT PREPARED”命令。通知各台数据库事务成功。

命令“PREPARE TRANSACTION”需要制定一个全局事务ID，由事务协调器生成，事务协调器会持久化这个全局事务ID，即使数据库重启，此事务既不会回滚，也不会丢失。这个全局事务ID是全局唯一的，除非这个事务已经完成。

#### 并发控制
需要解决的问题：在数据库中，并发控制是指在多个用户/进程/线程同时对数据库进行操作时，如何保证事务的一致性和隔离性的，同时最大程度地并发。

当多个用户/进程/线程同时对数据库进行操作时，会出现3种冲突情形：

* 读-读，不存在任何问题。
* 读-写，有隔离性问题，可能遇到脏读（会读到未提交的数据） ，不可重复读、幻读等。
* 写-写，可能丢失更新。

解决冲突有多种办法：

* 基于锁的并发控制，例如2PL，但开销比较高，且无法避免死锁，可以解决**读-写**和**写-写**问题。
* 多版本控制（MVCC）是一种用来解决**读-写**的无锁并发控制。避免了脏读和不可重复读和幻读。
* 乐观并发控制（OCC）是一种用来解决**写-写**的无锁并发控制。在提交事务前，检查一下事务开始后，有没有新提交改变，如果没有就提交，如果有就放弃并重试。适用于写冲突较少的场景。

多版本并发控制可以结合基于锁的并发控制来解决**写-写**冲突，也可以结合乐观并发控制解决**写-写**冲突。

并发控制模型有基于锁的并发控制和基于多版本的并发控制（MVCC）。封锁、时间戳、乐观并发控制（乐观锁，OCC）和悲观并发控制（悲观锁，PCC）是并发控制采用的主要技术手段。

##### 基于锁的并发控制
基本的封锁类型有两种：排它锁（X锁）和共享锁（S锁）。

* 排它锁：被加锁的对象只能被持有锁的事务读取和修改，其他事务无法在该对象上加其他锁，也不鞥读取和修改该对象。
* 共享锁：被加锁的对象只能被持有锁的事务读取，但是不能被修改，其他事务也可以在上面再加共享锁。

采用意向锁来描述行级锁和表级锁之间的关系。

更具体的锁可参考官方文档。

##### 基于多版本的并发控制
一般把基于锁的并发控制机制称为悲观机制，而把MVCC机制称为乐观机制。这是因为锁机制是一种预防性的机制，读会阻塞写，写也会阻塞读，当封锁粒度较大时，时间较长时并发性能差；而MVCC是一种后验性的机制，读不阻塞写，写不阻塞读，等到提交的时候才检验是否有冲突，由于没有锁，所以读写不会相互阻塞，避免了大粒度和长时间的锁定，提交并发性能。在MVCC中，每一个写操作创建一个新版本。

MVCC通过保存数据在某个时间点的**快照**，并控制元组的可见性来实现。

pg为每一个事物分配一个递增的、类型为int的整型数作为唯一的事务ID，称为xid。在pg内部数据结构中，每个元祖（行记录）有4个与事务可见性相关的隐藏列，分别是xmin、xmax、cmin和cmax，其中cmin和cmax分别是插入和删除该元祖的命令在十五中的命令序列标识，xmin、xmax与事务对其他事务的可见性相关，用于同一个事务中的可见性判断。

```SQL
create table tb1_mvcc(id serial primary key,ival int);
insert into tb1_mvcc (ival) values(1);
select xmin,xmax,cmin,cmax,id,ival from tb1_mvcc where id =1;
```

```
 xmin | xmax | cmin | cmax | id | ival
------+------+------+------+----+------
  877 |    0 |    0 |    0 |  1 |    1
(1 row)
```

其中xmin保存了创建和更新该行数据的事务的xid，xmax保存的是删除该行的xid。

###### 通过xmin决定事务的可见性
当插入一行数据时，pg会将插入这行数据的事务xid存储在xmin中。通过xmin值判断事务中插入的行记录对其他事务的可见性有两种情况：

1. 由回滚的事务或未提交的事务创建的行对于任何其他事务都是不可见的。

```SQL
test=# begin;
BEGIN
test=# select txid_current();
 txid_current
--------------
          878
(1 row)

test=# insert into tb1_mvcc (id, ival) values(7,7);
INSERT 0 1
test=# select xmin,xmax,cmin,cmax,id,ival from tb1_mvcc where id = 7;
 xmin | xmax | cmin | cmax | id | ival
------+------+------+------+----+------
  878 |    0 |    0 |    0 |  7 |    7
(1 row)
```

可以看出，xmin记录的是插入该行的数据id。

另开一个事务，执行：

```SQL
test=# begin;
BEGIN
test=# select txid_current();
 txid_current
--------------
          879
(1 row)

test=# select * from tb1_mvcc where id = 7;
 id | ival
----+------
(0 rows)

test=# end;
COMMIT
```

可以看出由于第一个事务并没有提交，所以第一个事务对第二个事务是不可见的。

2. 无论提交成功或回滚的事务，xid都会递增。对于重复读和可串行化隔离级别的事务，如果它的xid小于另外一个事务xid，即元祖的xmin小于另外一个事务的xmin，那么另外一个事务对这个事务是不可见的。

```SQL
test=# begin transaction isolation level repeatable read;
BEGIN
test=# select txid_current();
 txid_current
--------------
          880
(1 row)
```

另开一个事务，执行：

```SQL
test=# begin;
BEGIN
test=# select txid_current();
 txid_current
--------------
          881
(1 row)

test=# insert into tb1_mvcc (id,ival) values(7,7);
INSERT 0 1
test=# select xmin,xmax,cmin,cmax,id,ival from tb1_mvcc where id = 7;
 xmin | xmax | cmin | cmax | id | ival
------+------+------+------+----+------
  881 |    0 |    0 |    0 |  7 |    7
(1 row)

test=# commit;
COMMIT
```

第二个事务的xid是881，并插入了一个新数据，xmin记录了第二个事务的xid，第二个事务提交成功，在第一个事务中查询第二个事务提交的数据，如下所示：

```SQL
test=# select xmin,xmax,cmin,cmax,id,ival from tb1_mvcc where id = 7;
 xmin | xmax | cmin | cmax | id | ival
------+------+------+------+----+------
(0 rows)
```

可见，尽管第二个事务提交成功，但在第一个十五中并未能查询到第二个事务的数据，因为第一个事务的xid是880，第二个事务插入的数据的xmin值是881，因此对第一个事务不可见。

###### 通过xmax决定事务的可见性
通过xmax值判断事务的更新操作和删除操作对其他事务的可见性有这几种情况：

* 如果没有设置xmax值，该行对其他事务总是可见的。
* 如果它被设置为回滚事务的xid，该行对其他事务也是可见的。
* 如果它被设置为一个正在运行，没有COMMIT和ROLLBACK的事务xid，该行对其他事务是可见的。
* 如果它被设置为一个已提交的事务的xid，该行对这个已提交事务之后发起的所有事务都是不可见的。


#### 事务隔离级别实现（重点）

事务的机制是通过**快照**来实现的多版本并发控制（MVCC），不同的事务隔离级别创建读快照的时间点不同。

* 可重复读是每个事务重建读快照，整个事务存在期间都用这个快照。
* 读已提交是每条 SQL 创建读快照，在每个 SQL 语句开始执行的时候创建的。隔离作用域仅限该条 SQL 语句。
* 读未提交是不创建，直接返回记录上的最新值
* 串行化隔离级别下直接用加锁的方式来避免并行访问。避免写-写并发问题。

快照的格式是xmin:xmax:xip_list。其中：

* xmin是最早活跃的事务id，小于xmin的事务要么被提交并可见，要么回滚/丢弃。
* xmax是最后已结束的事务（COMMITED/ABORTED）的事务id+1。
* xip_list：在“拍摄”快照时仍进行中的事务id，该列表包含xmin和xmax之间的活动事务id。

对于当前的快照而言，可见性如下：

* 大于等于xmax，属于未来事务，不可见。
* 小于xmin的事务，视为已结束事务，可见。
* 大于等于xmin，小于xmax的事务，如果该事务未结束，不可见；否则，可见。

用例子说明：
1、假设当前的事务隔离级别是读已提交，能避免脏读，但可能出现不可重复读和幻读。**这个隔离级别下粒度是SQL**。每次执行一条SQL都会检查是否需要先更新快照。

```SQL
-- 事务1
test=# begin;
BEGIN
test=# select txid_current();
 txid_current
--------------
          901
(1 row)

test=# select txid_current_snapshot();
 txid_current_snapshot
-----------------------
 869:901:869
(1 row)

```

可以看出当前事务为901，快照为869:901:869。如果此时没有其他事务进行写操作，执行一条SQL：

```SQL
-- 事务1
test=# select xmin,xmax,* from tb1_mvcc;
 xmin | xmax | id | ival
------+------+----+------
  895 |    0 |  1 |    1
  897 |    0 |  2 |    2
(2 rows)

```

这两条数据的xmax都为0，代表这两条数据是最新的，xmin都在快照的xmin和xmax之间，且895和897这两个事务已经结束了，因此这两条数据对该快照而言是可见的。

假设此时另外一个事务，事务id为902，更新一条数据，但不提交。

```SQL
-- 事务2
test=# begin;
BEGIN
test=# select txid_current();
 txid_current
--------------
          902
(1 row)

test=# update tb1_mvcc set ival = 22 where id = 2;
UPDATE 1
```

这是查看事务1的快照，可以发现仍然是869:901:869。

```SQL
-- 事务1
test=# select txid_current_snapshot();
 txid_current_snapshot
-----------------------
 869:901:869
(1 row)
```

在事务1中，此时的数据中的xmax已经改变：

```SQL
-- 事务1
test=# select xmin,xmax,* from tb1_mvcc;
 xmin | xmax | id | ival
------+------+----+------
  895 |    0 |  1 |    1
  897 |  902 |  2 |    2
(2 rows)

```

xmax已经变成了902，这代表这条数据被事务id为902事务删除了，并插入了一条新的数据，这条数据的xmin为902，xmax为0，id为2，ival为22，这可以在事务2中看出：

```SQL
-- 事务2
test=# select xmin,xmax,* from tb1_mvcc;
 xmin | xmax | id | ival
------+------+----+------
  895 |    0 |  1 |    1
  902 |    0 |  2 |   22
(2 rows)
```

因为事务2的事务id902大于事务1快照869:901:869的xmax，属于未来事务，因此不可见。

如果此时事务2提交事务，在事务1查看此时快照发现快照发生了变化：

```SQL
-- 事务1
test=# select txid_current_snapshot();
 txid_current_snapshot
-----------------------
 869:903:869
(1 row)

test=# select xmin,xmax,* from tb1_mvcc;
 xmin | xmax | id | ival
------+------+----+------
  895 |    0 |  1 |    1
  902 |    0 |  2 |   22
(2 rows)
```

在事务1中查询可以发现已经能获取最新的数据了，该行数据的xmin是902，在快照869:903:869的xmin和xmax之间，而且902事务已经提交，因此对于这个快照，902事务更新的这条数据可见。

2、假设当前的事务隔离级别是重复读，能避免脏读、不可重复读和幻读。**这个隔离级别下粒度是事务**。只会在事务开始时“拍摄”一个快照，这个快照在这个事务中不会再改变。

在事务1中查询事务id和快照，此时事务id为903，快照为869:903:869：

```SQL
-- 事务1
test=# begin transaction isolation level repeatable read;
BEGIN
test=# select txid_current();
 txid_current
--------------
          903
(1 row)

test=# select txid_current_snapshot();
 txid_current_snapshot
-----------------------
 869:903:869
(1 row)
```

另开一个事务2，也查询事务id和快照，此时事务id为904，快照为869:903:869

```SQL
-- 事务2
test=# begin transaction isolation level repeatable read;
BEGIN
test=# select txid_current();
 txid_current
--------------
          904
(1 row)

test=# select txid_current_snapshot();
 txid_current_snapshot
-----------------------
 869:903:869
(1 row)

```

在事务2中更新数据：

```SQL
-- 事务2
test=# select * from tb1_mvcc;
 id | ival
----+------
  1 |    1
  2 |   22
(2 rows)

test=# update tb1_mvcc set ival = 2 where id = 2;
UPDATE 1
```

此时在事务1中查看数据，发现数据的xmax变为了事务2的事务id了：

```SQL
-- 事务1
test=# select xmin,xmax,* from tb1_mvcc;
 xmin | xmax | id | ival
------+------+----+------
  895 |    0 |  1 |    1
  902 |  904 |  2 |   22
```

在事务2提交事务后，查看事务1的数据和快照：

```SQL
test=# select xmin,xmax,* from tb1_mvcc;
 xmin | xmax | id | ival
------+------+----+------
  895 |    0 |  1 |    1
  902 |  904 |  2 |   22

test=# select txid_current_snapshot();
 txid_current_snapshot
-----------------------
 869:903:869
```

可以看出事务1数据的xmax已经变为了904了，但快照仍然不变，和刚启动事务时的快照一样。因为最新数据的事务id时904，大于事务1快照的xmax，属于未来事务，因此事务2的修改对于事务1不可见。


可见性的规则过于复杂，没必要研究。简单了解mvcc插入、删除和更新元组。

假设事务id为1的事务插入一条数据，则

```SQL
insert into test_table(id, ival) values(1, 1);
```

| xmin | xmax | id  | ival |
| ---- | ---- | --- | ---- |
| 1    | 0    | 1   | 1    |

假设事务id为2的事务更新id为1的数据：

```SQL
update test_table set ival = 11 where id = 1;
```

| xmin | xmax | id  | ival |
| ---- | ---- | --- | ---- |
| 1    | 2    | 1   | 1    |
| 2    | 0    | 1   | 11   |

假设事务id为3的事务删除id为1的数据

```SQL
delete from test_table where id = 1;
```

| xmin | xmax | id  | ival |
| ---- | ---- | --- | ---- |
| 1    | 2    | 1   | 1    |
| 2    | 3    | 1   | 11   |

假设事务id为4的事务更新id为1的数据两次：

```SQL
begin;
update test_table set ival = 11 where id = 1;
update test_table set ival = 12 where id = 1;
```

| xmin | xmax | id  | ival |
| ---- | ---- | --- | ---- |
| 1    | 4    | 1   | 1    |
| 4    | 4    | 1   | 11   |
| 4    | 0    | 1   | 12   |

MVCC的实现方法有两种：

* 写新数据是，把旧数据移到一个专门的地方（如回滚段），其他人读数据时，从回滚段中把旧数据读出来。
* 写数据时，旧数据不删除，把新数据插入。pg使用这种方法。

MVCC的优点：

* 使用MVCC，读操作不会阻塞写，写操作也不会阻塞读，提高了并发访问下的性能。
* 事务的回滚可立即完成，无论事务进行了多少操作。
* 数据可以进行大量更新，不像MySQL和Innodb引擎和Oracle那样需要保证回滚段不会被耗尽。

MVCC的缺点：

* 旧版本数据需要清理
* 旧版本数据过多导致查询变慢

MVCC实现了一种期待：读永远不堵塞写。但是也带来了一些问题：

* 因为不同的事务会看到不同版本的记录，所以PostgreSQL连那些可能过期的数据也要保留着；
当UPDATA时，真正地创建了一行新记录，而DELETE时，并不会真正地删除一行旧记录；
最终数据库中会存在一些对有事务永远不可见的记录，称作dead rows。
* 事务ID只能增加，它是个32bit，支持大约40亿个事务，达到最大值会从0重新开始；
这样带来一个逻辑问题：突然所有记录都变成了发生在将来的事务所产生的，而所有新事物也都没有办法访问这些旧记录了。

解决方法：VACUUM
PostgreSQL自带了auto_vacuum守护进程会在一个可配置的周期内自动执行清理，解决了这两个问题；
使用者需要留意这个auto_vacuum，以免发生不想要的结果；
vacuum命令也可以手动执行。


参考：
https://www.jianshu.com/p/04b542aeebac
http://www.interdb.jp/pg/index.html